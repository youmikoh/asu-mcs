{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project 1: Density Estimation and Classification - Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5000, 5000, 980, 1135]\n",
      "Your trainset and testset are generated successfully!\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "import scipy.io\n",
    "import math\n",
    "import geneNewData\n",
    "\n",
    "\n",
    "myID = \"5486\"  # your ID here\n",
    "geneNewData.geneData(myID)\n",
    "Numpyfile0 = scipy.io.loadmat(\"digit0_stu_train\" + myID + \".mat\")\n",
    "Numpyfile1 = scipy.io.loadmat(\"digit1_stu_train\" + myID + \".mat\")\n",
    "Numpyfile2 = scipy.io.loadmat(\"digit0_testset\" + \".mat\")\n",
    "Numpyfile3 = scipy.io.loadmat(\"digit1_testset\" + \".mat\")\n",
    "train0 = Numpyfile0.get(\"target_img\")\n",
    "train1 = Numpyfile1.get(\"target_img\")\n",
    "test0 = Numpyfile2.get(\"target_img\")\n",
    "test1 = Numpyfile3.get(\"target_img\")\n",
    "print([len(train0), len(train1), len(test0), len(test1)])\n",
    "print(\"Your trainset and testset are generated successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1: Feature extraction\n",
    "\n",
    "\n",
    "Assume features are independent of eachother and images are drawn from normal distribution\n",
    "\n",
    "- feature 1: average brightness of the image \n",
    "- feature 2: standard deviation of the brightness\n",
    "\n",
    "$$p(f_1 | \\,f_2, \\text{digit}) = p(f_1 | \\,\\text{digit})$$\n",
    "$$p(f_2 | \\,f_1, \\text{digit}) = p(f_2 | \\,\\text{digit})$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature1 = lambda img: numpy.mean(img)\n",
    "feature2 = lambda img: numpy.std(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(dtype('float64'), (5000, 2), (5000, 2))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train0_features = numpy.array([(feature1(img), feature2(img)) for img in train0])\n",
    "train1_features = numpy.array([(feature1(img), feature2(img)) for img in train1])\n",
    "\n",
    "train0_features.dtype, train0_features.shape, train1_features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2: Parameter calculation\n",
    "\n",
    "$$\\begin{array}{cc}\\hat{\\mu} = \\frac{ \\sum_i{x_i}}{n} && \\widehat{\\sigma^2} = \\frac{\\sum_i{(x_i - \\mu)^2}}{n} \\end{array}$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean_of_feature1_for_digit0: 44.20389362244898\n",
      "Variance_of_feature1_for_digit0: 116.7009513315956\n",
      "\n",
      "Mean_of_feature2_for_digit0: 87.41907699909902\n",
      "Variance_of_feature2_for_digit0: 102.46490855207279\n",
      "\n",
      "Mean_of_feature1_for_digit1: 19.43962244897959\n",
      "Variance_of_feature1_for_digit1: 31.98890083543315\n",
      "\n",
      "Mean_of_feature2_for_digit1: 61.44770668123185\n",
      "Variance_of_feature2_for_digit1: 83.54555141482662\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mean0_f1, var0_f1 = numpy.mean(train0_features[:, 0]), numpy.var(train0_features[:, 0])\n",
    "mean0_f2, var0_f2 = numpy.mean(train0_features[:, 1]), numpy.var(train0_features[:, 1])\n",
    "mean1_f1, var1_f1 = numpy.mean(train1_features[:, 0]), numpy.var(train1_features[:, 0])\n",
    "mean1_f2, var1_f2 = numpy.mean(train1_features[:, 1]), numpy.var(train1_features[:, 1])\n",
    "\n",
    "print(f\"Mean_of_feature1_for_digit0: {mean0_f1}\\nVariance_of_feature1_for_digit0: {var0_f1}\\n\")\n",
    "print(f\"Mean_of_feature2_for_digit0: {mean0_f2}\\nVariance_of_feature2_for_digit0: {var0_f2}\\n\")\n",
    "print(f\"Mean_of_feature1_for_digit1: {mean1_f1}\\nVariance_of_feature1_for_digit1: {var1_f1}\\n\")\n",
    "print(f\"Mean_of_feature2_for_digit1: {mean1_f2}\\nVariance_of_feature2_for_digit1: {var1_f2}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3: Na√Øve Bayes Classifier implementation & label predictions for test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test0_features = numpy.array([(feature1(img), feature2(img)) for img in test0])\n",
    "test1_features = numpy.array([(feature1(img), feature2(img)) for img in test1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train0_len, train1_len = len(train0_features), len(train1_features)\n",
    "train_len = train0_len + train1_len\n",
    "prior0, prior1 = train0_len / train_len, train1_len / train_len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normal probability density function\n",
    "\n",
    "$${\\displaystyle Norm(x, \\mu, \\sigma^2) = \\dfrac{1}{\\sqrt{2\\pi\\sigma^2}} {exp}^{- \\dfrac{{(x-\\mu)^2}}{{2\\sigma^2}}} }$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normal_pdf(x, mean, var):\n",
    "    d = 1 / numpy.sqrt(2 * numpy.pi * var)\n",
    "    n = numpy.exp(-((x - mean) ** 2) / (2 * var))\n",
    "    return d * n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bayesian probability\n",
    "\n",
    "$${\\displaystyle p(C_{k}\\mid \\mathbf {x} )={\\frac {p(C_{k})\\ p(\\mathbf {x} \\mid C_{k})}{p(\\mathbf {x} )}}\\, \\Leftrightarrow \\, \\text{posterior}={\\frac {{\\text{prior}}\\times {\\text{likelihood}}}{\\text{evidence}}} }$$\n",
    "\n",
    "\n",
    "$$\n",
    "\\begin{array}{rll}\n",
    "\\text{prior} \\times \\text{likelihood} \\Leftrightarrow (C_{k},x_{1},\\ldots ,x_{n}) &= p(x_{1},\\ldots ,x_{n},C_{k}) \\\\\n",
    "&= p(x_{1}\\mid x_{2},\\ldots ,x_{n},C_{k}) \\cdot p(x_{2},\\ldots ,x_{n},C_{k}) \\\\\n",
    "&= p(x_{1}\\mid x_{2},\\ldots ,x_{n},C_{k}) \\cdot p(x_{2}\\mid x_{3},\\ldots ,x_{n},C_{k}) \\cdot p(x_{3},\\ldots ,x_{n},C_{k}) \\\\\n",
    "&= \\cdots \\\\\n",
    "&= p(x_{1}\\mid x_{2},\\ldots ,x_{n},C_{k}) \\cdot p(x_{2}\\mid x_{3},\\ldots ,x_{n},C_{k}) \\cdots p(x_{n-1}\\mid x_{n},C_{k}) \\cdot p(x_{n}\\mid C_{k}) \\cdot p(C_{k}) \n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "#### Naive conditional independence\n",
    "\n",
    "$$\n",
    "\\begin{array}{lll}\n",
    "p(x_{i}\\mid x_{i+1},\\ldots ,x_{n},C_{k})=p(x_{i}\\mid C_{k}) \\Rightarrow & p(C_{k}\\mid x_{1},\\ldots ,x_{n}) &\\propto p(C_{k},x_{1},\\ldots ,x_{n}) \\\\\n",
    "&&\\propto p(C_{k}) \\cdot p(x_{1}\\mid C_{k}) \\cdot p(x_{2}\\mid C_{k}) \\cdot p(x_{3}\\mid C_{k}) \\cdots \\\\\n",
    "&&\\propto p(C_{k}) \\prod p(x_{i}\\mid C_{k})\n",
    "\\end{array}\n",
    "$$\n",
    "$$\n",
    "\\begin{array}{lll}\n",
    "\\text{posterior} \\Leftrightarrow p(C_{k}\\mid x_{1},\\ldots ,x_{n}) = \\dfrac{ p(C_{k}) \\prod p(x_{i}\\mid C_{k})}{p(\\mathbf{x})} & \\text{where} & p(\\mathbf{x}) = \\sum p(C_{k}) \\cdot p(\\mathbf{x} \\mid C_{k}) \\Leftrightarrow \\text{evidence}\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "#### Classifier\n",
    "\n",
    "\n",
    "\n",
    "$${\\widehat {C_k}}={\\underset {k}{\\operatorname {argmax} }}\\ p(C_{k})\\displaystyle \\prod_i p(x_{i}\\mid C_{k})\\, = \\, {\\underset {k}{\\operatorname {argmax} }}\\, \\{\\text{posterior}\\} $$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifier(test_features, prior0, prior1):\n",
    "    labels = []\n",
    "    for test_f1, test_f2 in test_features:\n",
    "        likelihood0 = normal_pdf(test_f1, mean0_f1, var0_f1) * normal_pdf(test_f2, mean0_f2, var0_f2)\n",
    "        likelihood1 = normal_pdf(test_f1, mean1_f1, var1_f1) * normal_pdf(test_f2, mean1_f2, var1_f2)\n",
    "        evidence = likelihood0 * prior0 + likelihood1 * prior1\n",
    "\n",
    "        posterior0 = (likelihood0 * prior0) / evidence\n",
    "        posterior1 = (likelihood1 * prior1) / evidence\n",
    "        classes = numpy.array([posterior0, posterior1])\n",
    "        labels.append(classes.argmax())\n",
    "\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(899, 1048)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test0_labels = classifier(test0_features, prior0, prior1)\n",
    "test1_labels = classifier(test1_features, prior0, prior1)\n",
    "\n",
    "test0_labels.count(0), test1_labels.count(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4: Accuracy calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy_for_digit0testset: 0.9173469387755102\n",
      "Accuracy_for_digit1testset: 0.9233480176211454\n"
     ]
    }
   ],
   "source": [
    "Accuracy_for_digit0testset = test0_labels.count(0) / len(test0_labels)\n",
    "Accuracy_for_digit1testset = test1_labels.count(1) / len(test1_labels)\n",
    "\n",
    "print(f\"Accuracy_for_digit0testset: {Accuracy_for_digit0testset}\")\n",
    "print(f\"Accuracy_for_digit1testset: {Accuracy_for_digit1testset}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
